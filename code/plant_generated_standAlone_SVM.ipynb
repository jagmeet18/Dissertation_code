{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499d70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,MaxPool2D,Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "from os import listdir\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "import pickle\n",
    "import cv2\n",
    "from os import listdir\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5791e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None :\n",
    "            img_gan = cv2.resize(image, (32,32))\n",
    "            return img_to_array(img_gan)\n",
    "        else :\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4395fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_plant_imgs(directory_root):\n",
    "    image_list, label_list = [], []\n",
    "    try:\n",
    "        print(\"[INFO] Loading images ...\")\n",
    "        root_dir = listdir(directory_root)\n",
    "        #print(root_dir)\n",
    "        for plant_folder in root_dir :\n",
    "            # remove .DS_Store from list\n",
    "            if plant_folder == \".DS_Store\" :\n",
    "                root_dir.remove(directory)\n",
    "\n",
    "\n",
    "        for plant_folder in root_dir :\n",
    "    #         print(\"on plant folder\")\n",
    "            plant_image_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
    "\n",
    "\n",
    "\n",
    "            for single_image in plant_image_list :\n",
    "\n",
    "    #             print(\"in plant folder\")\n",
    "                if single_image == \".DS_Store\" :\n",
    "                    plant_image_list.remove(single_image)\n",
    "\n",
    "            for image in plant_image_list[:1000]:\n",
    "    #             print(\"getting img path\")\n",
    "                image_directory = f\"{directory_root}/{plant_folder}/{image}\"\n",
    "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True or image_directory.endswith(\".png\") == True or image_directory.endswith(\".PNG\") == True:\n",
    "    #                 print(\"checking if img correct format\")\n",
    "                    gan_img = convert_image_to_array(image_directory)\n",
    "                    image_list.append(gan_img)\n",
    "                    label_list.append(plant_folder)\n",
    "\n",
    "        print(\"[INFO] Image loading completed\")\n",
    "        return image_list, label_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe67175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enhanced_data = 'Enhanced_tomato_DCGAN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf29cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "# enhanced_image_list , enhanced_label_list = extract_plant_imgs(enhanced_data)\n",
    "orignal_img_list, orignal_label_list = extract_plant_imgs('Orignal_plant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e2a36184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "GAN_image_list, GAN_label_list = extract_plant_imgs('BiGANxSRGAN_plant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "857bf4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_image_list_GAN = np.array(GAN_image_list, dtype = np.float16) / 255.0\n",
    "normalized_image_list_orignal = np.array(orignal_img_list, dtype = np.float16) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f416870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[0 0 0 ... 9 9 9]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "image_labels_GAN = label_encoder.fit_transform(GAN_label_list)\n",
    "n_classes = len(label_encoder.classes_)\n",
    "print(n_classes)\n",
    "print(image_labels_GAN)\n",
    "\n",
    "# Convert the labels to one-hot encoded vectors\n",
    "image_labels_GAN = to_categorical(image_labels_GAN, num_classes=n_classes)\n",
    "print(image_labels_GAN[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "53669922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[0 0 0 ... 9 9 9]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "image_labels_orignal = label_encoder.fit_transform(orignal_label_list)\n",
    "n_classes = len(label_encoder.classes_)\n",
    "print(n_classes)\n",
    "print(image_labels_orignal)\n",
    "\n",
    "# Convert the labels to one-hot encoded vectors\n",
    "image_labels_orignal = to_categorical(image_labels_orignal, num_classes=n_classes)\n",
    "print(image_labels_orignal[3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0a294033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making the training and testing split with 30% of the dataset as testing set\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "print(\"making the training and testing split with 30% of the dataset as testing set\")\n",
    "GAN_x_train, GAN_x_test, GAN_y_train, GAN_y_test = train_test_split(normalized_image_list_GAN, image_labels_GAN, test_size=0.3, shuffle=True,random_state = 42)\n",
    "\n",
    "orignal_x_train, orignal_x_test, orignal_y_train, orignal_y_test = train_test_split(normalized_image_list_orignal, image_labels_orignal, test_size=0.3, shuffle=True,random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d8e689c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_gen = LabelBinarizer()\n",
    "# image_labels = label_gen.fit_transform(enhanced_label_list)\n",
    "# pickle.dump(label_gen,open('label_transform.pkl', 'wb'))\n",
    "# n_classes = len(label_gen.classes_)\n",
    "# print(n_classes)\n",
    "# print(image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c56a3abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# print(\"making the training and testing split with 30% of the dataset as testing set\")\n",
    "# x_train, x_test, y_train, y_test = train_test_split(new_image_list, image_labels, test_size=0.3, shuffle=True,random_state = 42) \n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e63d9281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 16, 16, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 77,098\n",
      "Trainable params: 77,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, padding = \"same\",activation = \"relu\",kernel_size=3, strides = 2,input_shape=(32,32,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides = 2))\n",
    "\n",
    "model.add(Conv2D(filters = 32, padding = \"same\",activation = \"relu\",kernel_size=3))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides = 2))\n",
    "\n",
    "# model.add(Conv2D(filters = 32, padding = \"same\",activation = \"relu\",kernel_size=3))\n",
    "# model.add(MaxPool2D(pool_size=(2,2),strides = 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "\n",
    "#Output layer\n",
    "model.add(Dense(10,kernel_regularizer=l2(0.01),activation = \"linear\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "59812175",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"squared_hinge\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3767c074",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "219/219 [==============================] - 2s 5ms/step - loss: 0.4358 - accuracy: 0.2626\n",
      "Epoch 2/15\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.2575 - accuracy: 0.6460\n",
      "Epoch 3/15\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1790 - accuracy: 0.8106\n",
      "Epoch 4/15\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1398 - accuracy: 0.8700\n",
      "Epoch 5/15\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.1116 - accuracy: 0.9103\n",
      "Epoch 6/15\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0929 - accuracy: 0.9316\n",
      "Epoch 7/15\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0790 - accuracy: 0.9486\n",
      "Epoch 8/15\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0671 - accuracy: 0.9596\n",
      "Epoch 9/15\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0601 - accuracy: 0.9644\n",
      "Epoch 10/15\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0550 - accuracy: 0.9729\n",
      "Epoch 11/15\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0496 - accuracy: 0.9753\n",
      "Epoch 12/15\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0471 - accuracy: 0.9773\n",
      "Epoch 13/15\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0426 - accuracy: 0.9804\n",
      "Epoch 14/15\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0393 - accuracy: 0.9807\n",
      "Epoch 15/15\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0360 - accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(GAN_x_train,GAN_y_train,epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b9ef0e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 11.166666666666666\n",
      "Precision: 18.940036056853167\n",
      "Recall: 10.985955435166158\n",
      "F1-score: 7.1096126643397834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(orignal_x_test)\n",
    "\n",
    "y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "# y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calculate the true labels for the test set\n",
    "y_true = orignal_y_test\n",
    "\n",
    "accuracy = accuracy_score(orignal_y_test, y_pred_binary)\n",
    "precision = precision_score(orignal_y_test, y_pred_binary, average='macro')\n",
    "recall = recall_score(orignal_y_test, y_pred_binary, average='macro')\n",
    "f1 = f1_score(orignal_y_test, y_pred_binary, average='macro')\n",
    "# conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy * 100)\n",
    "print(\"Precision:\", precision * 100)\n",
    "print(\"Recall:\", recall * 100)\n",
    "print(\"F1-score:\", f1 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1832bee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.83333333333333\n",
      "Precision: 100.0\n",
      "Recall: 99.66101694915255\n",
      "F1-score: 99.830220713073\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# y_prob = model.predict(x_test)\n",
    "# y_pred = np.where(y_prob[:len(x_test)] >= 0.5, 1, 0)\n",
    "\n",
    "# # y_pred = model.predict(x_test)\n",
    "# # print(y_pred)\n",
    "# # # mse = mean_squared_error(y_test, y_pred)\n",
    "# # # print(mse)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print(\"Accuracy:\", accuracy * 100)\n",
    "# print(\"Precision:\", precision * 100)\n",
    "# print(\"Recall:\", recall * 100)\n",
    "# print(\"F1-score:\", f1 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5321e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"plant_tomato_standAlone_DCGAN_svm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87140ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0a0b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
