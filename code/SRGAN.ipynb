{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe07318c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow \n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from keras import Model\n",
    "from keras.layers import Conv2D, PReLU,BatchNormalization, Flatten\n",
    "from keras.layers import UpSampling2D, LeakyReLU, Dense, Input, add\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5990e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_block(input_dim):\n",
    "    model = Conv2D(64, (3,3), padding = 'same' )(input_dim)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = PReLU(shared_axes = [1,2])(model)\n",
    "    model = Conv2D(64, (3,3), padding = 'same' )(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    return add([input_dim, model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e1707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_block(input_dim):\n",
    "    model = Conv2D(256,(3,3), strides=1, padding = 'same')(input_dim)\n",
    "    model = UpSampling2D(size = (2,2))(model)\n",
    "    model = PReLU(shared_axes=[1, 2])(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee6a2164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input, res_range = 1,upscale_range=1):\n",
    "    model = Conv2D(64,(9,9), strides=1, padding = 'same')(input)\n",
    "    model = PReLU(shared_axes = [1,2])(model)\n",
    "    model1 = model\n",
    "    for i in range(res_range):\n",
    "        model = res_block(model)\n",
    "    model = Conv2D(64, (3,3), padding = 'same' )(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = add([model,model1])\n",
    "    for i in range(upscale_range):\n",
    "        model  =upscale_block(model)\n",
    "    output = Conv2D(3, (9,9),  padding='same')(model)\n",
    "    return Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f16ff5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for building discriminator\n",
    "def discrim_block(input_dim, fmaps = 64, strides = 1):\n",
    "    model = Conv2D(fmaps, (3,3), padding = 'same', strides  = strides)(input_dim)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = LeakyReLU()(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab9594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input):\n",
    "    model = Conv2D(64,(3,3),padding='same')(input)\n",
    "    model = LeakyReLU()(model)\n",
    "    model = discrim_block(model, strides = 2)\n",
    "    model = discrim_block(model, fmaps  = 128)\n",
    "    model = discrim_block(model, fmaps = 128, strides = 2)\n",
    "    model = discrim_block(model, fmaps=256)\n",
    "    model = discrim_block(model, fmaps=256, strides=2)\n",
    "    model = discrim_block(model, fmaps=512)\n",
    "    model = discrim_block(model, fmaps=512, strides=2)\n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024)(model)\n",
    "    model = LeakyReLU(alpha = 0.2)(model)\n",
    "    out = Dense(1, activation='sigmoid')(model)\n",
    "    return Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55fb9e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "def build_vgg(hr_shape):\n",
    "    vgg = VGG19(weights=\"imagenet\", include_top=False, input_shape=hr_shape)\n",
    "\n",
    "    return Model(inputs=vgg.inputs, outputs=vgg.layers[10].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6c3c088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
    "    gen_img = gen_model(lr_ip)\n",
    "\n",
    "    gen_features = vgg(gen_img)\n",
    "\n",
    "    disc_model.trainable = False\n",
    "    validity = disc_model(gen_img)\n",
    "\n",
    "    return Model(inputs=[lr_ip, hr_ip], outputs=[validity, gen_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd02fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "import pickle\n",
    "import cv2\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3205fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None :\n",
    "            img_lr = cv2.resize(image, (32,32))\n",
    "            img_hr = cv2.resize(image, (128,128))\n",
    "            return img_to_array(img_lr), img_to_array(img_hr)\n",
    "        else :\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b03cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImgeList(directory_root):\n",
    "    \n",
    "    image_list_lr,image_list_hr, label_list = [], [], []\n",
    "    try:\n",
    "        print(\"[INFO] Loading images ...\")\n",
    "        root_dir = listdir(directory_root)\n",
    "        #print(root_dir)\n",
    "        for plant_folder in root_dir :\n",
    "            # remove .DS_Store from list\n",
    "            if plant_folder == \".DS_Store\" :\n",
    "                root_dir.remove(directory)\n",
    "\n",
    "        for plant_folder in root_dir :\n",
    "    #         print(\"on plant folder\")\n",
    "            plant_image_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
    "            for single_image in plant_image_list :\n",
    "\n",
    "    #             print(\"in plant folder\")\n",
    "                if single_image == \".DS_Store\" :\n",
    "                    plant_image_list.remove(single_image)\n",
    "\n",
    "            for image in plant_image_list[:6000]:\n",
    "    #             print(\"getting img path\")\n",
    "                image_directory = f\"{directory_root}/{plant_folder}/{image}\"\n",
    "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True:\n",
    "    #                 print(\"checking if img correct format\")\n",
    "                    lr_img, hr_img = convert_image_to_array(image_directory)\n",
    "                    image_list_lr.append(lr_img)\n",
    "                    image_list_hr.append(hr_img)\n",
    "                    label_list.append(plant_folder)\n",
    "        print(\"[INFO] Image loading completed\")  \n",
    "        return image_list_lr, image_list_hr, label_list\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "671c7f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "directory_root = 'DataB_strawberry'\n",
    "image_list_lr,image_list_hr, label_list = getImgeList(directory_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3e5a835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3327, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "normalized_image_list_lr = np.array(image_list_lr, dtype = np.float16) / 127.5 - 1.\n",
    "normalized_image_list_hr = np.array(image_list_hr, dtype = np.float16) / 127.5 - 1.\n",
    "print(normalized_image_list_hr.shape)\n",
    "# label_gen = LabelBinarizer()\n",
    "# image_labels = label_gen.fit_transform(label_list)\n",
    "# pickle.dump(label_gen,open('label_transform.pkl', 'wb'))\n",
    "# n_classes = len(label_gen.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "957b4fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making the training and testing split with 30% of the dataset as testing set\n",
      "(2994, 128, 128, 3)\n",
      "(2994, 32, 32, 3)\n",
      "(333, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "print(\"making the training and testing split with 30% of the dataset as testing set\")\n",
    "hr_train, hr_test, lr_train, lr_test = train_test_split(normalized_image_list_hr, normalized_image_list_lr, test_size=0.1, random_state = 42) \n",
    "print(hr_train.shape)\n",
    "print(lr_train.shape)\n",
    "print(hr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42f1d7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "hr_shape = (hr_train.shape[1], hr_train.shape[2], hr_train.shape[3])\n",
    "lr_shape = (lr_train.shape[1], lr_train.shape[2], lr_train.shape[3])\n",
    "print(hr_shape)\n",
    "print(lr_shape)\n",
    "\n",
    "lr_ip = Input(shape=lr_shape)\n",
    "hr_ip = Input(shape=hr_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b54b505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 64)   15616       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu (PReLU)                 (None, 32, 32, 64)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 64)   36928       p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_1 (PReLU)               (None, 32, 32, 64)   64          batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 64)   36928       p_re_lu_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 64)   0           p_re_lu[0][0]                    \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 64)   36928       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_2 (PReLU)               (None, 32, 32, 64)   64          batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36928       p_re_lu_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           add[0][0]                        \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_3 (PReLU)               (None, 32, 32, 64)   64          batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36928       p_re_lu_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           add_1[0][0]                      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   36928       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_4 (PReLU)               (None, 32, 32, 64)   64          batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 64)   36928       p_re_lu_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           add_2[0][0]                      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 64)   36928       add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_5 (PReLU)               (None, 32, 32, 64)   64          batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 64)   256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 64)   0           add_3[0][0]                      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 64)   36928       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_6 (PReLU)               (None, 32, 32, 64)   64          batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 64)   0           add_4[0][0]                      \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 64)   36928       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 64)   256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_7 (PReLU)               (None, 32, 32, 64)   64          batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 64)   0           add_5[0][0]                      \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 64)   36928       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 64)   256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_8 (PReLU)               (None, 32, 32, 64)   64          batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 64)   256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 64)   0           add_6[0][0]                      \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 64)   36928       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_9 (PReLU)               (None, 32, 32, 64)   64          batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 64)   256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 64)   0           add_7[0][0]                      \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 64)   36928       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 64)   256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_10 (PReLU)              (None, 32, 32, 64)   64          batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 32, 32, 64)   0           add_8[0][0]                      \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 64)   36928       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_11 (PReLU)              (None, 32, 32, 64)   64          batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 64)   256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 64)   0           add_9[0][0]                      \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 64)   36928       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 64)   256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_12 (PReLU)              (None, 32, 32, 64)   64          batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 64)   0           add_10[0][0]                     \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 64)   36928       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_13 (PReLU)              (None, 32, 32, 64)   64          batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 64)   256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 64)   0           add_11[0][0]                     \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 64)   36928       add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_14 (PReLU)              (None, 32, 32, 64)   64          batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 32, 32, 64)   0           add_12[0][0]                     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 64)   36928       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_15 (PReLU)              (None, 32, 32, 64)   64          batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 64)   256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 32, 32, 64)   0           add_13[0][0]                     \n",
      "                                                                 batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 64)   36928       add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_16 (PReLU)              (None, 32, 32, 64)   64          batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 64)   36928       p_re_lu_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 32, 32, 64)   0           add_14[0][0]                     \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 64)   36928       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 32, 32, 64)   0           batch_normalization_32[0][0]     \n",
      "                                                                 p_re_lu[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 256)  147712      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 64, 256)  0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_17 (PReLU)              (None, 64, 64, 256)  256         up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 256)  590080      p_re_lu_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_18 (PReLU)              (None, 128, 128, 256 256         up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 128, 128, 3)  62211       p_re_lu_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,044,291\n",
      "Trainable params: 2,040,067\n",
      "Non-trainable params: 4,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = generator(lr_ip,res_range=16,upscale_range= 2)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8a28254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              33555456  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 38,249,281\n",
      "Trainable params: 38,245,569\n",
      "Non-trainable params: 3,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = discriminator(hr_ip)\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9110c396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "=================================================================\n",
      "Total params: 2,325,568\n",
      "Trainable params: 2,325,568\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vgg = build_vgg((128,128,3))\n",
    "print(vgg.summary())\n",
    "vgg.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d1de765",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e215fc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 128, 128, 3)  2044291     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 1)            38249281    model[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 32, 32, 256)  2325568     model[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 42,619,140\n",
      "Trainable params: 2,040,067\n",
      "Non-trainable params: 40,579,073\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# def ssim_loss(y_true, y_pred):\n",
    "#     return 1 - tf.image.ssim(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "# gan_model.compile(loss=[ssim_loss, \"mse\"], loss_weights=[1e-3, 1], optimizer=\"adam\")\n",
    "\n",
    "gan_model.compile(loss=[\"binary_crossentropy\", \"mse\"], loss_weights=[1e-3, 1], optimizer=\"adam\")\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28112db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_lr_batches = []\n",
    "train_hr_batches = []\n",
    "for it in range(int(lr_train.shape[0] / batch_size)):\n",
    "    start_idx = it * batch_size\n",
    "    end_idx = start_idx + batch_size\n",
    "    train_lr_batches.append(lr_train[start_idx:end_idx])\n",
    "    train_hr_batches.append(hr_train[start_idx:end_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e32c5e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2994/2994 [14:07<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 g_loss: [[[65.168495 65.74567  66.21369  ... 66.68457  66.1483   65.38935 ]\n",
      "  [65.51296  66.20262  66.68318  ... 67.44454  66.870964 65.9178  ]\n",
      "  [65.785034 66.566826 67.09446  ... 68.28584  67.60481  66.41464 ]\n",
      "  ...\n",
      "  [66.733894 68.01024  68.962456 ... 75.21889  73.618965 70.51854 ]\n",
      "  [66.08423  67.157646 68.06895  ... 73.81875  71.81543  69.04371 ]\n",
      "  [65.42128  66.26919  67.02612  ... 71.4706   69.74731  67.40804 ]]] d_loss: [1.42228134 0.63360053]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2994/2994 [13:48<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 g_loss: [[[ 1981646.2   4530213.5   7692141.5  ...   595560.75   329886.\n",
      "     147410.92]\n",
      "  [ 3252556.5   6276489.5  10157165.   ...   827589.06   454401.97\n",
      "     223904.64]\n",
      "  [ 5044168.    9216059.   14044315.   ...  1280836.9    699293.5\n",
      "     340894.47]\n",
      "  ...\n",
      "  [48469836.   63951372.   65506964.   ... 79323120.   54038496.\n",
      "   31558440.  ]\n",
      "  [40471492.   58973328.   69838024.   ... 90657960.   54707752.\n",
      "   29059894.  ]\n",
      "  [28046826.   47854388.   59997024.   ... 86762208.   52473016.\n",
      "   24047502.  ]]] d_loss: [0.50589223 0.74549098]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2994/2994 [13:45<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 g_loss: [[[58.984726 59.059975 59.06111  ... 59.068157 59.067036 58.98436 ]\n",
      "  [59.064907 59.16151  59.13734  ... 59.150635 59.17715  59.06848 ]\n",
      "  [59.071217 59.156723 59.130783 ... 59.142864 59.17543  59.081444]\n",
      "  ...\n",
      "  [59.16209  59.309505 59.298676 ... 59.315136 59.331215 59.17762 ]\n",
      "  [59.146496 59.3201   59.327263 ... 59.34501  59.348713 59.17447 ]\n",
      "  [59.03275  59.16731  59.191273 ... 59.206802 59.195034 59.064926]]] d_loss: [0.11784588 0.95774883]\n"
     ]
    }
   ],
   "source": [
    "#using VGG content loss\n",
    "import keras.backend as K\n",
    "from keras.losses import mean_squared_error\n",
    "epochs = 3\n",
    "#Enumerate training over epochs\n",
    "for e in range(epochs):\n",
    "    content_weight = 0.01\n",
    "    fake_label = np.zeros((batch_size, 1)) # Assign a label of 0 to all fake (generated images)\n",
    "    real_label = np.ones((batch_size,1)) # Assign a label of 1 to all real images.\n",
    "    \n",
    "    #Create empty lists to populate gen and disc losses. \n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    #Enumerate training over batches. \n",
    "    for b in tqdm(range(len(train_hr_batches))):\n",
    "        lr_imgs = train_lr_batches[b] #Fetch a batch of LR images for training\n",
    "        hr_imgs = train_hr_batches[b] #Fetch a batch of HR images for training\n",
    "        \n",
    "        fake_imgs = generator.predict_on_batch(lr_imgs) #Fake images\n",
    "        \n",
    "        #First, train the discriminator on fake and real HR images. \n",
    "        discriminator.trainable = True\n",
    "        d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
    "        d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
    "        \n",
    "        #Now, train the generator by fixing discriminator as non-trainable\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        #Average the discriminator loss, just for reporting purposes. \n",
    "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real) \n",
    "        \n",
    "        #Extract VGG features, to be used towards calculating loss\n",
    "        image_features = vgg.predict(hr_imgs)\n",
    "     \n",
    "        #Train the generator via GAN. \n",
    "        #Remember that we have 2 losses, adversarial loss and content (VGG) loss\n",
    "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
    "        \n",
    "        # Calculate content loss using VGG features of generated images\n",
    "        gen_features = vgg.predict(fake_imgs)\n",
    "        content_loss = content_weight * mean_squared_error(image_features, gen_features)\n",
    "        # Add content loss to generator loss\n",
    "        g_loss += content_loss\n",
    "        \n",
    "        #Save losses to a list so we can average and report. \n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_loss)\n",
    "        \n",
    "    #Convert the list of losses to an array to make it easy to average    \n",
    "    g_losses = np.array(g_losses)\n",
    "    d_losses = np.array(d_losses)\n",
    "    \n",
    "    #Calculate the average losses for generator and discriminator\n",
    "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
    "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
    "    \n",
    "    #Report the progress during training. \n",
    "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
    "\n",
    "    if (e+1) % 10 == 0: #Change the frequency for model saving, if needed\n",
    "        #Save the generator after every n epochs (Usually 10 epochs)\n",
    "        generator.save(\"gen_e_\"+ str(e+1) +\".h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434c6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# from keras.losses import MeanSquaredError\n",
    "# from keras.applications.vgg19 import VGG19\n",
    "# from keras.models import Model\n",
    "# from keras_contrib.losses import DSSIMObjective\n",
    "\n",
    "# # Set the weight for content loss\n",
    "# content_weight = 0.01\n",
    "\n",
    "# def srgan_loss(hr_image, sr_image, disc_generated_output):\n",
    "#     # Define loss functions\n",
    "#     mse_loss = MeanSquaredError()(hr_image, sr_image)\n",
    "#     ssim_loss = DSSIMObjective()(hr_image, sr_image)\n",
    "\n",
    "#     # Calculate adversarial loss\n",
    "#     adversarial_loss = 1 - K.mean(disc_generated_output)\n",
    "\n",
    "#     # Calculate content loss\n",
    "#     vgg = VGG19(include_top=False, weights='imagenet')\n",
    "#     vgg.trainable = False\n",
    "#     content_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block5_conv4').output)\n",
    "#     hr_features = content_model(hr_image)\n",
    "#     sr_features = content_model(sr_image)\n",
    "#     content_loss = content_weight * MeanSquaredError()(hr_features, sr_features)\n",
    "\n",
    "#     # Combine the losses\n",
    "#     total_loss = adversarial_loss + ssim_loss + content_loss\n",
    "\n",
    "#     return total_loss\n",
    "\n",
    "\n",
    "# epochs = 10\n",
    "# #Enumerate training over epochs\n",
    "# for e in range(epochs):\n",
    "    \n",
    "#     fake_label = np.zeros((batch_size, 1)) # Assign a label of 0 to all fake (generated images)\n",
    "#     real_label = np.ones((batch_size,1)) # Assign a label of 1 to all real images.\n",
    "    \n",
    "#     #Create empty lists to populate gen and disc losses. \n",
    "#     g_losses = []\n",
    "#     d_losses = []\n",
    "    \n",
    "#     #Enumerate training over batches. \n",
    "#     for b in tqdm(range(len(train_hr_batches))):\n",
    "#         lr_imgs = train_lr_batches[b] #Fetch a batch of LR images for training\n",
    "#         hr_imgs = train_hr_batches[b] #Fetch a batch of HR images for training\n",
    "        \n",
    "#         fake_imgs = generator.predict_on_batch(lr_imgs) #Fake images\n",
    "        \n",
    "#         #First, train the discriminator on fake and real HR images. \n",
    "#         discriminator.trainable = True\n",
    "#         d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
    "#         d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
    "        \n",
    "#         #Now, train the generator by fixing discriminator as non-trainable\n",
    "#         discriminator.trainable = False\n",
    "        \n",
    "#         #Average the discriminator loss, just for reporting purposes. \n",
    "#         d_loss = 0.5 * np.add(d_loss_gen, d_loss_real) \n",
    "        \n",
    "#         #Train the generator via GAN. \n",
    "#         #Remember that we have 3 losses, adversarial loss, content (VGG) loss and SSIM loss\n",
    "#         g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, hr_imgs, hr_imgs])\n",
    "        \n",
    "#         #Save losses to a list so we can average and report. \n",
    "#         d_losses.append(d_loss)\n",
    "#         g_losses.append(g_loss)\n",
    "        \n",
    "#     #Convert the list of losses to an array to make it easy to average    \n",
    "#     g_losses = np.array(g_losses)\n",
    "#     d_losses = np.array(d_losses)\n",
    "    \n",
    "#     #Calculate the average losses for generator and discriminator\n",
    "#     g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
    "#     d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
    "    \n",
    "#     #Report the progress during training. \n",
    "#     print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
    "\n",
    "#     if (e+\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e8c1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usign ssim loss\n",
    "# from skimage import structural_similarity as ssim\n",
    "\n",
    "# epochs = 4\n",
    "\n",
    "# #Enumerate training over epochs\n",
    "# for e in range(epochs):\n",
    "    \n",
    "#     fake_label = np.zeros((batch_size, 1)) # Assign a label of 0 to all fake (generated images)\n",
    "#     real_label = np.ones((batch_size,1)) # Assign a label of 1 to all real images.\n",
    "    \n",
    "#     #Create empty lists to populate gen and disc losses. \n",
    "#     g_losses = []\n",
    "#     d_losses = []\n",
    "    \n",
    "#     #Enumerate training over batches. \n",
    "#     for b in tqdm(range(len(train_hr_batches))):\n",
    "#         lr_imgs = train_lr_batches[b] #Fetch a batch of LR images for training\n",
    "#         hr_imgs = train_hr_batches[b] #Fetch a batch of HR images for training\n",
    "        \n",
    "#         fake_imgs = generator.predict_on_batch(lr_imgs) #Fake images\n",
    "        \n",
    "#         #First, train the discriminator on fake and real HR images. \n",
    "#         discriminator.trainable = True\n",
    "#         d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
    "#         d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
    "        \n",
    "#         #Now, train the generator by fixing discriminator as non-trainable\n",
    "#         discriminator.trainable = False\n",
    "        \n",
    "#         #Average the discriminator loss, just for reporting purposes. \n",
    "#         d_loss = 0.5 * np.add(d_loss_gen, d_loss_real) \n",
    "        \n",
    "#         #Calculate SSIM loss between HR images and generated images\n",
    "#         ssim_loss = np.mean([ssim(hr_imgs[i], fake_imgs[i], multichannel=True) for i in range(batch_size)])\n",
    "     \n",
    "#         #Train the generator via GAN. \n",
    "#         #Remember that we have 2 losses, adversarial loss and SSIM loss\n",
    "#         g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, ssim_loss])\n",
    "        \n",
    "#         #Save losses to a list so we can average and report. \n",
    "#         d_losses.append(d_loss)\n",
    "#         g_losses.append(g_loss)\n",
    "        \n",
    "#     #Convert the list of losses to an array to make it easy to average    \n",
    "#     g_losses = np.array(g_losses)\n",
    "#     d_losses = np.array(d_losses)\n",
    "    \n",
    "#     #Calculate the average losses for generator and discriminator\n",
    "#     g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
    "#     d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
    "    \n",
    "#     #Report the progress during training. \n",
    "#     print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
    "\n",
    "#     if (e+1) % 10 == 0: #Change the frequency for model saving, if needed\n",
    "#         #Save the generator after every n epochs (Usually 10 epochs)\n",
    "#         generator.save(\"gen_e_\"+ str(e+1) +\".h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da22ec77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2994 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\backend.py:5000 binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:245 sigmoid_cross_entropy_with_logits_v2\n        return sigmoid_cross_entropy_with_logits(\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:132 sigmoid_cross_entropy_with_logits\n        raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\n    ValueError: logits and labels must have the same shape ((1, 1) vs (1, 0))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#First, train the discriminator on fake and real HR images. \u001b[39;00m\n\u001b[0;32m     21\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mtrainable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m d_loss_gen \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_imgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(hr_imgs, real_label)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#Now, train the generator by fixing discriminator as non-trainable\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\training.py:1856\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1852\u001b[0m   iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x,\n\u001b[0;32m   1853\u001b[0m                                                 y, sample_weight,\n\u001b[0;32m   1854\u001b[0m                                                 class_weight)\n\u001b[0;32m   1855\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 1856\u001b[0m   logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_metrics:\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3038\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3035\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[1;32m-> 3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3459\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3449\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(\n\u001b[0;32m   3450\u001b[0m     status\u001b[38;5;241m=\u001b[39mag_status, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autograph_options):\n\u001b[0;32m   3451\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3454\u001b[0m   \u001b[38;5;66;03m# and 2. there's no provided input signature\u001b[39;00m\n\u001b[0;32m   3455\u001b[0m   \u001b[38;5;66;03m# and 3. there's been a cache miss for this calling context\u001b[39;00m\n\u001b[0;32m   3456\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_relax_shapes \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   3457\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   3458\u001b[0m       call_context_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed):\n\u001b[1;32m-> 3459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_define_function_with_shape_relaxation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3460\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_key_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3462\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m   3463\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_graph_function(args, kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3381\u001b[0m, in \u001b[0;36mFunction._define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3374\u001b[0m   (relaxed_arg_specs, relaxed_kwarg_specs) \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   3375\u001b[0m       (args, kwargs), relaxed_arg_specs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3376\u001b[0m   (args, kwargs) \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   3377\u001b[0m       (relaxed_arg_specs, relaxed_kwarg_specs),\n\u001b[0;32m   3378\u001b[0m       flat_args,\n\u001b[0;32m   3379\u001b[0m       expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 3381\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3382\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelaxed_arg_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3383\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39marg_relaxed[rank_only_cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (graph_function, [\n\u001b[0;32m   3386\u001b[0m     t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten((args, kwargs), expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (ops\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   3388\u001b[0m                       resource_variable_ops\u001b[38;5;241m.\u001b[39mBaseResourceVariable))\n\u001b[0;32m   3389\u001b[0m ])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3293\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3295\u001b[0m ]\n\u001b[0;32m   3296\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3297\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3306\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3310\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3311\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3312\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3313\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3314\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3315\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1007\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1012\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    665\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 668\u001b[0m     out \u001b[38;5;241m=\u001b[39m weak_wrapped_fn()\u001b[38;5;241m.\u001b[39m__wrapped__(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    669\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:994\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    993\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    995\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\backend.py:5000 binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:245 sigmoid_cross_entropy_with_logits_v2\n        return sigmoid_cross_entropy_with_logits(\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\jagme\\anaconda3\\envs\\new_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:132 sigmoid_cross_entropy_with_logits\n        raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\n    ValueError: logits and labels must have the same shape ((1, 1) vs (1, 0))\n"
     ]
    }
   ],
   "source": [
    "# orignal\n",
    "epochs = 1\n",
    "#Enumerate training over epochs\n",
    "for e in range(epochs):\n",
    "    \n",
    "    fake_label = np.zeros((batch_size, 1)) # Assign a label of 0 to all fake (generated images)\n",
    "    real_label = np.ones((batch_size,1)) # Assign a label of 1 to all real images.\n",
    "    \n",
    "    #Create empty lists to populate gen and disc losses. \n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    #Enumerate training over batches. \n",
    "    for b in tqdm(range(len(train_hr_batches))):\n",
    "        lr_imgs = train_lr_batches[b] #Fetch a batch of LR images for training\n",
    "        hr_imgs = train_hr_batches[b] #Fetch a batch of HR images for training\n",
    "        \n",
    "        fake_imgs = generator.predict_on_batch(lr_imgs) #Fake images\n",
    "        \n",
    "        #First, train the discriminator on fake and real HR images. \n",
    "        discriminator.trainable = True\n",
    "        d_loss_gen = discriminator.train_on_batch(fake_imgs, fake_label)\n",
    "        d_loss_real = discriminator.train_on_batch(hr_imgs, real_label)\n",
    "        \n",
    "        #Now, train the generator by fixing discriminator as non-trainable\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        #Average the discriminator loss, just for reporting purposes. \n",
    "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real) \n",
    "        \n",
    "        #Extract VGG features, to be used towards calculating loss\n",
    "        image_features = vgg.predict(hr_imgs)\n",
    "     \n",
    "        #Train the generator via GAN. \n",
    "        #Remember that we have 2 losses, adversarial loss and content (VGG) loss\n",
    "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs], [real_label, image_features])\n",
    "        \n",
    "        #Save losses to a list so we can average and report. \n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_loss)\n",
    "        \n",
    "    #Convert the list of losses to an array to make it easy to average    \n",
    "    g_losses = np.array(g_losses)\n",
    "    d_losses = np.array(d_losses)\n",
    "    \n",
    "    #Calculate the average losses for generator and discriminator\n",
    "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
    "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
    "    \n",
    "    #Report the progress during training. \n",
    "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)\n",
    "\n",
    "    if (e+1) % 10 == 0: #Change the frequency for model saving, if needed\n",
    "        #Save the generator after every n epochs (Usually 10 epochs)\n",
    "        generator.save(\"gen_e_\"+ str(e+1) +\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7542bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None :\n",
    "            img_gan = cv2.resize(image, (32,32))\n",
    "            return img_to_array(img_gan)\n",
    "        else :\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c561267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "directory_root = 'DCGAN_tomato_bacterial_final'\n",
    "image_list_GAN, label_list = [], []\n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "    root_dir = listdir(directory_root)\n",
    "    #print(root_dir)\n",
    "    for plant_folder in root_dir :\n",
    "        # remove .DS_Store from list\n",
    "        if plant_folder == \".DS_Store\" :\n",
    "            root_dir.remove(directory)\n",
    "            \n",
    "\n",
    "    for plant_folder in root_dir :\n",
    "#         print(\"on plant folder\")\n",
    "        plant_image_list = listdir(f\"{directory_root}/{plant_folder}\")\n",
    "        \n",
    "     \n",
    "        \n",
    "        for single_image in plant_image_list :\n",
    "            \n",
    "#             print(\"in plant folder\")\n",
    "            if single_image == \".DS_Store\" :\n",
    "                plant_image_list.remove(single_image)\n",
    "\n",
    "        for image in plant_image_list[:2000]:\n",
    "#             print(\"getting img path\")\n",
    "            image_directory = f\"{directory_root}/{plant_folder}/{image}\"\n",
    "            if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True or image_directory.endswith(\".png\") == True or image_directory.endswith(\".PNG\") == True:\n",
    "#                 print(\"checking if img correct format\")\n",
    "                gan_img = convert_image_to_array(image_directory)\n",
    "                image_list_GAN.append(gan_img)\n",
    "                label_list.append(plant_folder)\n",
    "                    \n",
    "    print(\"[INFO] Image loading completed\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3561d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_image_list_GAN = np.array(image_list_GAN, dtype = np.float16) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd552a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(normalized_image_list_GAN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbc938d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.compiled_metrics == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed6ef07d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator.compile()\n",
    "generator.save('generator_leafScorch_strawberry_SRGAN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3942731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_gen = keras.models.load_model('generator_leafScorch_strawberry_SRGAN6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66682033",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = loaded_gen.predict(lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0b3d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import array_to_img\n",
    "# test_results = test_results * 255.0\n",
    "test_results = 0.5 * test_results + 0.5\n",
    "for i in range(len(test_results)):\n",
    "    img = array_to_img((test_results[i, :,:,:]))\n",
    "    img.save(os.path.join('SRGAN_gen',f'generated_img_epoch_{i}.png')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a53b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(lst,parts):\n",
    "    n = len(lst)\n",
    "    n_thirds = n // parts\n",
    "    remainder = n % parts\n",
    "    \n",
    "    parts_list = []\n",
    "    start = 0\n",
    "    \n",
    "    for i in range(3):\n",
    "        end = start + n_thirds\n",
    "        \n",
    "        if i < remainder:\n",
    "            end += 1\n",
    "        \n",
    "        parts_list.append(lst[start:end])\n",
    "        start = end\n",
    "    \n",
    "    return parts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b6c5f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "partitions = split_list(normalized_image_list_GAN, 3)\n",
    "part1 = partitions[0]\n",
    "part2 = partitions[1]\n",
    "part3 = partitions[2]\n",
    "print(normalized_image_list_GAN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc790b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from keras.preprocessing.image import array_to_img\n",
    "\n",
    "\n",
    "def predict_parts(gen_model, part_list):\n",
    "    generated_imgs = loaded_gen.predict(part_list)\n",
    "    generated_imgs = generated_imgs * 255.0\n",
    "    return generated_imgs\n",
    "\n",
    "def save_to_folder(l1,l2,l3):\n",
    "    check_point = 0\n",
    "    for i in range(len(l1)):\n",
    "        img = array_to_img((l1[i, :,:,:]))\n",
    "        img.save(os.path.join('SRGAN_X_DCGAN_tomato_bacterial',f'generated_img_epoch_{i}.png')) \n",
    "        check_point = i\n",
    "    for i in range(len(l2)):\n",
    "        img = array_to_img((l2[i, :,:,:]))\n",
    "        img.save(os.path.join('SRGAN_X_DCGAN_tomato_bacterial',f'generated_img_epoch_{check_point + i}.png')) \n",
    "        check_point = i\n",
    "    for i in range(len(l3)):\n",
    "        img = array_to_img((l3[i, :,:,:]))\n",
    "        img.save(os.path.join('SRGAN_X_DCGAN_tomato_bacterial',f'generated_img_epoch_{check_point + i}.png')) \n",
    "        check_point = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f71155eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_imgs1 = predict_parts(loaded_gen, part1)\n",
    "gen_imgs2 = predict_parts(loaded_gen, part2)\n",
    "gen_imgs3 = predict_parts(loaded_gen, part3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a59610a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_folder(gen_imgs1, gen_imgs2, gen_imgs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f5ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
