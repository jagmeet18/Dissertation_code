{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490f4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "import gdown\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a0e741e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4445 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "data= tf.keras.utils.image_dataset_from_directory('DataB_pepper', label_mode = None,  batch_size = 16, image_size = (32,32))\n",
    "len(data)\n",
    "data = data.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af600f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in data:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2764ea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_iterator = data.as_numpy_iterator()\n",
    "#batch = data_iterator.next()\n",
    "# class 0 in the batch is real images of the plants\n",
    "# shape of the images is (128,64,64,3)\n",
    "# batch size is 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f1e3bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.MapDataset"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbd2960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 398,657\n",
      "Trainable params: 398,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "################# DISCRIMINATOR NETWORK ######################\n",
    "# model name\n",
    "discriminator = keras.Sequential(name = \"discriminator\")\n",
    "# input layer\n",
    "discriminator.add(keras.Input(shape=(32,32,3),))\n",
    "# hidden layer 1\n",
    "discriminator.add(layers.Conv2D(64, kernel_size = (4,4), strides = (2,2), padding=\"same\"))\n",
    "discriminator.add(layers.LeakyReLU(0.2))\n",
    "# hidden layer 2\n",
    "discriminator.add(layers.Conv2D(128, kernel_size = (4,4), strides = (2,2), padding=\"same\"))\n",
    "discriminator.add(layers.LeakyReLU(0.2))\n",
    "# hidden layer 3\n",
    "discriminator.add(layers.Conv2D(128, kernel_size = (4,4), strides = (2,2), padding=\"same\"))\n",
    "discriminator.add(layers.LeakyReLU(0.2))\n",
    "# output layer \n",
    "discriminator.add(layers.Flatten())\n",
    "discriminator.add(layers.Dropout(0.2))\n",
    "discriminator.add(layers.Dense(1, activation=\"tanh\"))\n",
    "# summary of the model\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1144f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "# plot_model(discriminator, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97a9c269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8192)              1056768   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 3)         19203     \n",
      "=================================================================\n",
      "Total params: 1,862,787\n",
      "Trainable params: 1,862,787\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#################### GENERATOR NETWORK ###########################\n",
    "generator = keras.Sequential()\n",
    "# input layer\n",
    "generator.add(layers.Input(shape=(128),))\n",
    "# hidden layer 1 ~ staring with 8 * 8 * 128\n",
    "generator.add(layers.Dense(8 * 8 * 128))\n",
    "generator.add(layers.Reshape((8,8,128)))\n",
    "# hidden layer 2 ~ upsampling to 16 * 16\n",
    "generator.add(layers.Conv2DTranspose(128, kernel_size = (4,4), strides = (2,2), padding = \"same\"))\n",
    "generator.add(layers.LeakyReLU(0.2))\n",
    "# hidden layer 3 ~ upsampling to 32 * 32\n",
    "generator.add(layers.Conv2DTranspose(256, kernel_size = (4,4), strides = (2,2), padding= \"same\"))\n",
    "generator.add(layers.LeakyReLU(0.2))\n",
    "# hidden layer 4 ~ upsampling to 64 * 64\n",
    "#generator.add(layers.Conv2DTranspose(512, kernel_size = (4,4), strides = (2,2), padding = \"same\"))\n",
    "#generator.add(layers.LeakyReLU(0.2))\n",
    "# output layer \n",
    "generator.add(layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"tanh\"))\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1f94799",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### TRAINING LOOP #######################\n",
    "\n",
    "##### SET UP LOSS AND OPTEMIZERS \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "# DCGAN pepper\n",
    "g_opt = Adam(learning_rate = 0.00025)\n",
    "d_opt = Adam(learning_rate = 0.000070)\n",
    "\n",
    "# strawberry\n",
    "# g_opt = Adam(learning_rate = 0.00035)\n",
    "# d_opt = Adam(learning_rate = 0.000075)\n",
    "\n",
    "# g_opt = Adam(learning_rate = 0.00045)\n",
    "# d_opt = Adam(learning_rate = 0.000075)\n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()\n",
    "\n",
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_opt, g_opt, d_loss, g_loss):\n",
    "        super().compile()\n",
    "        self.d_opt = d_opt\n",
    "        self.g_opt = g_opt\n",
    "        self.d_loss = d_loss\n",
    "        self.g_loss = g_loss\n",
    "        \n",
    "\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "        \n",
    "        # Combine them with real images\n",
    "        #combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        #labels = tf.concat(\n",
    "        #    [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        #)\n",
    "        # Add random noise to the labels - important trick!\n",
    "        #labels += 0.10 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:   \n",
    "            #predictions = self.discriminator(combined_images)\n",
    "            #total_d_loss = self.d_loss(labels, predictions)\n",
    "            is_real = self.discriminator(real_images, training = True)\n",
    "            is_gen = self.discriminator(generated_images, training = True)\n",
    "            combined = tf.concat([is_real, is_gen], axis = 0)\n",
    "            Lable_combined = tf.concat([tf.zeros_like(is_real), tf.ones_like(is_gen)], axis = 0)\n",
    "            \n",
    "#             noise_real = tf.random.uniform(tf.shape(is_real))\n",
    "#             noise_gen =  tf.random.uniform(tf.shape(is_gen))\n",
    "            \n",
    "            noise_real = 0.25 * tf.random.uniform(tf.shape(is_real))\n",
    "            noise_gen = -0.15 * tf.random.uniform(tf.shape(is_gen))\n",
    "#             noise_gen = -0.25 * tf.random.uniform(tf.shape(is_gen))\n",
    "            \n",
    "            Lable_combined += tf.concat([noise_real, noise_gen], axis = 0)\n",
    "            total_d_loss = self.d_loss(Lable_combined, combined)\n",
    "            \n",
    "        grads = tape.gradient(total_d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_opt.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            total_g_loss = self.g_loss(misleading_labels, predictions)\n",
    "        grads = tape.gradient(total_g_loss, self.generator.trainable_weights)\n",
    "        self.g_opt.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        \n",
    "        return {\n",
    "            \"d_loss\": total_d_loss,\n",
    "            \"g_loss\": total_g_loss,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31f136c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('DCGAN_Bacterial_trial', f'generated_img_epoch_{epoch}_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15064fb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "278/278 [==============================] - 12s 39ms/step - d_loss: 1.4231 - g_loss: 0.2029\n",
      "Epoch 2/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.8690 - g_loss: 0.5522\n",
      "Epoch 3/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7924 - g_loss: 0.6407\n",
      "Epoch 4/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7668 - g_loss: 0.6643\n",
      "Epoch 5/100\n",
      "278/278 [==============================] - 9s 30ms/step - d_loss: 0.7495 - g_loss: 0.6906\n",
      "Epoch 6/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7349 - g_loss: 0.7039\n",
      "Epoch 7/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7319 - g_loss: 0.7063\n",
      "Epoch 8/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7296 - g_loss: 0.7179\n",
      "Epoch 9/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7286 - g_loss: 0.7043\n",
      "Epoch 10/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7183 - g_loss: 0.7317\n",
      "Epoch 11/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7172 - g_loss: 0.7256\n",
      "Epoch 12/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7189 - g_loss: 0.7241\n",
      "Epoch 13/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7138 - g_loss: 0.7333\n",
      "Epoch 14/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7167 - g_loss: 0.7352\n",
      "Epoch 15/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7138 - g_loss: 0.7215\n",
      "Epoch 16/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7124 - g_loss: 0.7369\n",
      "Epoch 17/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7142 - g_loss: 0.7258\n",
      "Epoch 18/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7158 - g_loss: 0.7327\n",
      "Epoch 19/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7110 - g_loss: 0.7275\n",
      "Epoch 20/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7100 - g_loss: 0.7387\n",
      "Epoch 21/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7092 - g_loss: 0.7349\n",
      "Epoch 22/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7088 - g_loss: 0.7373\n",
      "Epoch 23/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7065 - g_loss: 0.7337\n",
      "Epoch 24/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7086 - g_loss: 0.7373\n",
      "Epoch 25/100\n",
      "278/278 [==============================] - 10s 35ms/step - d_loss: 0.7074 - g_loss: 0.7483\n",
      "Epoch 26/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7072 - g_loss: 0.7367\n",
      "Epoch 27/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7026 - g_loss: 0.7477\n",
      "Epoch 28/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7100 - g_loss: 0.7406\n",
      "Epoch 29/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7061 - g_loss: 0.7342\n",
      "Epoch 30/100\n",
      "278/278 [==============================] - 10s 35ms/step - d_loss: 0.7066 - g_loss: 0.7399\n",
      "Epoch 31/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7061 - g_loss: 0.7475\n",
      "Epoch 32/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7059 - g_loss: 0.7384\n",
      "Epoch 33/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7060 - g_loss: 0.7381\n",
      "Epoch 34/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7049 - g_loss: 0.7428\n",
      "Epoch 35/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7022 - g_loss: 0.7526\n",
      "Epoch 36/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7048 - g_loss: 0.7485\n",
      "Epoch 37/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7058 - g_loss: 0.7394\n",
      "Epoch 38/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7042 - g_loss: 0.7472\n",
      "Epoch 39/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7035 - g_loss: 0.7464\n",
      "Epoch 40/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7052 - g_loss: 0.7451\n",
      "Epoch 41/100\n",
      "278/278 [==============================] - 10s 35ms/step - d_loss: 0.7039 - g_loss: 0.7415\n",
      "Epoch 42/100\n",
      "278/278 [==============================] - 9s 32ms/step - d_loss: 0.7024 - g_loss: 0.7472\n",
      "Epoch 43/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7021 - g_loss: 0.7457\n",
      "Epoch 44/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7047 - g_loss: 0.7520\n",
      "Epoch 45/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7014 - g_loss: 0.7472\n",
      "Epoch 46/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7004 - g_loss: 0.7427\n",
      "Epoch 47/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7012 - g_loss: 0.7509\n",
      "Epoch 48/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6988 - g_loss: 0.7495\n",
      "Epoch 49/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7022 - g_loss: 0.7492\n",
      "Epoch 50/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7012 - g_loss: 0.7534\n",
      "Epoch 51/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7036 - g_loss: 0.7425\n",
      "Epoch 52/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7042 - g_loss: 0.7439\n",
      "Epoch 53/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7021 - g_loss: 0.7451\n",
      "Epoch 54/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6984 - g_loss: 0.7526\n",
      "Epoch 55/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7012 - g_loss: 0.7470\n",
      "Epoch 56/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.7015 - g_loss: 0.7456\n",
      "Epoch 57/100\n",
      "278/278 [==============================] - 9s 34ms/step - d_loss: 0.6969 - g_loss: 0.7455\n",
      "Epoch 58/100\n",
      "278/278 [==============================] - 9s 34ms/step - d_loss: 0.6975 - g_loss: 0.7509\n",
      "Epoch 59/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6968 - g_loss: 0.7501\n",
      "Epoch 60/100\n",
      "278/278 [==============================] - 9s 33ms/step - d_loss: 0.6996 - g_loss: 0.7455\n",
      "Epoch 61/100\n",
      "278/278 [==============================] - 10s 35ms/step - d_loss: 0.6961 - g_loss: 0.7536\n",
      "Epoch 62/100\n",
      "278/278 [==============================] - 10s 35ms/step - d_loss: 0.6986 - g_loss: 0.7588\n",
      "Epoch 63/100\n",
      "278/278 [==============================] - 9s 33ms/step - d_loss: 0.6984 - g_loss: 0.7476\n",
      "Epoch 64/100\n",
      "278/278 [==============================] - 9s 34ms/step - d_loss: 0.6973 - g_loss: 0.7470\n",
      "Epoch 65/100\n",
      "278/278 [==============================] - 9s 34ms/step - d_loss: 0.6971 - g_loss: 0.7515\n",
      "Epoch 66/100\n",
      "278/278 [==============================] - 9s 33ms/step - d_loss: 0.6957 - g_loss: 0.7565\n",
      "Epoch 67/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6975 - g_loss: 0.7553\n",
      "Epoch 68/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6985 - g_loss: 0.7575\n",
      "Epoch 69/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6950 - g_loss: 0.7550\n",
      "Epoch 70/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6947 - g_loss: 0.7575\n",
      "Epoch 71/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6939 - g_loss: 0.7700\n",
      "Epoch 72/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6986 - g_loss: 0.7540\n",
      "Epoch 73/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6942 - g_loss: 0.7615\n",
      "Epoch 74/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6923 - g_loss: 0.7569\n",
      "Epoch 75/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6981 - g_loss: 0.7690\n",
      "Epoch 76/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6925 - g_loss: 0.7683\n",
      "Epoch 77/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6950 - g_loss: 0.7659\n",
      "Epoch 78/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6886 - g_loss: 0.7760\n",
      "Epoch 79/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6885 - g_loss: 0.7691\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6921 - g_loss: 0.7720\n",
      "Epoch 81/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6937 - g_loss: 0.7952\n",
      "Epoch 82/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6930 - g_loss: 0.7730\n",
      "Epoch 83/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6867 - g_loss: 0.7814\n",
      "Epoch 84/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6919 - g_loss: 0.7881\n",
      "Epoch 85/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6890 - g_loss: 0.7923\n",
      "Epoch 86/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6871 - g_loss: 0.7891\n",
      "Epoch 87/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6881 - g_loss: 0.7904\n",
      "Epoch 88/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6881 - g_loss: 0.7839\n",
      "Epoch 89/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6936 - g_loss: 0.7651\n",
      "Epoch 90/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6999 - g_loss: 0.7759\n",
      "Epoch 91/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6873 - g_loss: 0.8051\n",
      "Epoch 92/100\n",
      "278/278 [==============================] - 9s 32ms/step - d_loss: 0.6807 - g_loss: 0.8505\n",
      "Epoch 93/100\n",
      "278/278 [==============================] - 9s 31ms/step - d_loss: 0.6900 - g_loss: 0.8076\n",
      "Epoch 94/100\n",
      "278/278 [==============================] - 9s 32ms/step - d_loss: 0.6779 - g_loss: 0.8143\n",
      "Epoch 95/100\n",
      "278/278 [==============================] - 9s 32ms/step - d_loss: 0.6806 - g_loss: 0.8162\n",
      "Epoch 96/100\n",
      "278/278 [==============================] - 9s 32ms/step - d_loss: 0.6709 - g_loss: 0.8446\n",
      "Epoch 97/100\n",
      "278/278 [==============================] - 9s 32ms/step - d_loss: 0.6911 - g_loss: 0.8016\n",
      "Epoch 98/100\n",
      "278/278 [==============================] - 9s 32ms/step - d_loss: 0.6778 - g_loss: 0.8183\n",
      "Epoch 99/100\n",
      "278/278 [==============================] - 9s 32ms/step - d_loss: 0.7013 - g_loss: 0.7937\n",
      "Epoch 100/100\n",
      "278/278 [==============================] - 9s 32ms/step - d_loss: 0.6852 - g_loss: 0.8243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d5f11d0850>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 100\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=128)\n",
    "gan.compile(d_opt, g_opt, d_loss, g_loss)\n",
    "gan.fit(data, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=128)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0ea3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_latent_vectors = tf.random.normal(shape=(16, 128))\n",
    "generated_images = generator.predict(random_latent_vectors)\n",
    "generated_images *= 255\n",
    "for i in range(16):\n",
    "    img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "    img.save(os.path.join('DCGAN_GEN', f'generated_img_epoch_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7efa4c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator.compiled_metrics == None\n",
    "generator.compile()\n",
    "generator.save('generator_bacterial_pepper_DCGAN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35941d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_gen = keras.models.load_model('generator_bacterial_pepper_DCGAN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5880ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_latent_vectors2 = tf.random.normal(shape=(2000, 128))\n",
    "generated_images = loaded_gen.predict(random_latent_vectors2)\n",
    "generated_images *= 255\n",
    "for i in range(2000):\n",
    "    img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "    img.save(os.path.join('DCGAN_pepper_bacterial_final', f'generated_img_epoch_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f19d0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.5347177  -0.7065127  -1.6114981  ... -2.287704   -0.8297936\n",
      "  -0.47491738]\n",
      " [-0.0037844  -0.08391918  0.1929763  ...  0.9431547   1.1112481\n",
      "   0.49122465]\n",
      " [ 0.37282747  0.705518   -0.1990936  ...  0.11986952 -0.6540281\n",
      "  -0.97849387]\n",
      " ...\n",
      " [ 0.4873934  -1.0083574   0.28027666 ... -0.6912557   1.2657646\n",
      "   2.5886927 ]\n",
      " [ 0.93032753  1.0765502  -0.83591175 ... -0.8548026   0.37978745\n",
      "  -1.2077094 ]\n",
      " [-0.7782833   0.38312474  2.338798   ... -0.47822246 -0.03043891\n",
      "   1.2092308 ]], shape=(16, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(random_latent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c684d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
